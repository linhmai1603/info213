{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 213: Data Science Programming 2\n",
    "___\n",
    "\n",
    "### Week 4: Naive Bayes and Probability\n",
    "___\n",
    "\n",
    "### 9:30-10:50am, Mon. July 16, and Wed. July 18, 2018\n",
    "---\n",
    "\n",
    "**Question:**\n",
    "- How to do fast and straigthforward probabilistic predictions?\n",
    "\n",
    "\n",
    "**Objectives:**\n",
    "- Define the problem of using conditional probabilities for classification\n",
    "- Describe the assumptions in Naive Bayes classification\n",
    "- Estimate the prior probabilities for Naive Bayes classification\n",
    "- Explain smoothing techiques in estimation\n",
    "- Implement Naive Bayes classification from scratch\n",
    "- Apply Naive Bayes methods in the Scikit Learn package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Naive Bayes models are a group of extremely fast and simple classification algorithms that are often suitable for very high-dimensional datasets. Because they are so fast and have so few tunable parameters, they end up being very useful as a quick-and-dirty baseline for a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Classification\n",
    "\n",
    "Naive Bayes classifiers are built on Bayesian classification methods.\n",
    "These rely on Bayes's theorem, which is an equation describing the relationship of conditional probabilities of statistical quantities.\n",
    "In Bayesian classification, we're interested in finding the probability of a label given some observed features, which we can write as $P(L~|~{\\rm features})$.\n",
    "Bayes's theorem tells us how to express this in terms of quantities we can compute more directly:\n",
    "\n",
    "$$\n",
    "P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}{P({\\rm features})}\n",
    "$$\n",
    "\n",
    "If we are trying to decide between two labels—let's call them $L_1$ and $L_2$—then one way to make this decision is to compute the ratio of the posterior probabilities for each label:\n",
    "\n",
    "$$\n",
    "\\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)}\n",
    "$$\n",
    "\n",
    "All we need now is some model by which we can compute $P({\\rm features}~|~L_i)$ for each label.\n",
    "Such a model is called a *generative model* because it specifies the hypothetical random process that generates the data.\n",
    "Specifying this generative model for each label is the main piece of the training of such a Bayesian classifier.\n",
    "The general version of such a training step is a very difficult task, but we can make it simpler through the use of some simplifying assumptions about the form of this model.\n",
    "\n",
    "This is where the \"naive\" in \"naive Bayes\" comes in: if we make very naive assumptions about the generative model for each label, we can find a rough approximation of the generative model for each class, and then proceed with the Bayesian classification.\n",
    "Different types of naive Bayes classifiers rest on different naive assumptions about the data.\n",
    "\n",
    "**Naive Assumption** Given a lable L and a set of data containing n features. The event \"the data contains a feature $f_i$ is independent of the events of the data containing any other features\". In other words, the features of the data are mutually independent. With the properties of conditional probabilities, we can write $P(f_1, f_2, ..., f_n|L) = P(f_1|L)\\times P(f_2|L)\\times ...\\times P(f_n|L)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Really Dumb Spam Filter\n",
    "\n",
    "Imagine a “universe” that consists of receiving a message chosen randomly from all\n",
    "possible messages. Let S be the event “the message is spam” and V be the event “the\n",
    "message contains the word viagra” and R be the event \"the message contains the word Rolex.\". Then Bayes’s Theorem tells us that the probability\n",
    "that the message is spam conditional on containing the word viagra and Rolex is:\n",
    "\n",
    "$P(S|V, R) = \\frac{P(V, R|S)\\times P(S)}{P(V, R)}$\n",
    "\n",
    "By the Naive assumption, we can write it as:\n",
    "\n",
    "$P(S|V, R) = \\frac{P(V, R|S)\\times P(S)}{P(V, R)} = \\frac{P(V|S)\\times P(R|S)\\times P(S)}{P(V, R)}$\n",
    "\n",
    "Given a set of spaming and non-spamming emails, we can estimate the quantities $P(V|S)$, $P(R|S)$, $P(S)$, and $P(V, R)$ by counting the number of occurences of each event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "It is hard to do data science without some sort of understanding of probability and its\n",
    "mathematics. For our purposes you should think of probability as a way of quantifying the uncertainty\n",
    "associated with events chosen from a some universe of events. The universe\n",
    "consists of all possible outcomes. And any subset of these outcomes is an event; for\n",
    "example, “the die rolls a one” or “the die rolls an even number.”\n",
    "\n",
    "Notationally, we write $P(E)$ to mean “the probability of the event $E$.”\n",
    "We’ll use probability theory to build models. We’ll use probability theory to evaluate\n",
    "models. We’ll use probability theory all over the place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence and Independence\n",
    "Roughly speaking, we say that two events E and F are dependent if knowing something\n",
    "about whether E happens gives us information about whether F happens (and\n",
    "vice versa). Otherwise they are independent.\n",
    "\n",
    "Mathematically, we say that two events E and F are independent if the probability that\n",
    "they both happen is the product of the probabilities that each one happens:\n",
    "\n",
    "$P(E, F) = P(E)\\times P(F)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Probability\n",
    "Given a set of possible events $S$. The probabilities of events in $S$ must satisfy the following properties:\n",
    "1. $P(a) \\geq 0$ for $a\\in S$\n",
    "2. $\\sum_{a\\in S} P(a) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability\n",
    "When two events E and F are independent, then by definition we have:\n",
    "\n",
    "$P(E, F) = P(E)\\times P(F)$\n",
    "\n",
    "If they are not necessarily independent (and if the probability of F is not zero), then\n",
    "we define the probability of E “conditional on F” as:\n",
    "\n",
    "$P(E|F) = P(E, F) /P(F)$\n",
    "\n",
    "You should think of this as the probability that E happens, given that we know that F happens.\n",
    "We often rewrite this as:\n",
    "\n",
    "$P(E, F) = P(E|F)\\times P(F)$\n",
    "\n",
    "When E and F are independent, you can check that this gives:\n",
    "\n",
    "$P(E|F) = P(E)$\n",
    "\n",
    "which is the mathematical way of expressing that knowing F occurred gives us no\n",
    "additional information about whether E occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example \n",
    "One common tricky example involves a family with two (unknown) children.\n",
    "If we assume that:\n",
    "1. Each child is equally likely to be a boy or a girl\n",
    "2. The gender of the second child is independent of the gender of the first child\n",
    "\n",
    "then the event “no girls” has probability 1/4, the event “one girl, one boy” has probability\n",
    "1/2, and the event “two girls” has probability 1/4.\n",
    "\n",
    "OK. Let us consider the following two events:\n",
    "1. what is the probability of the event “both children are girls” (B) conditional\n",
    "on the event “the older child is a girl” (G)? \n",
    "2. what is the probability of the event “both children are girls” conditional\n",
    "on the event “at least one of the children is a girl” (L)?\n",
    "\n",
    "If you have gotten the answers, let us simulate the events and check your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import random\n",
    "def random_kid():\n",
    "    return random.choice([\"boy\", \"girl\"])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_kid():\n",
    "    return random.choice([\"boy\", \"girl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "both_girls = 0\n",
    "older_girl = 0\n",
    "either_girl = 0\n",
    "girl_boy = 0\n",
    "\n",
    "random.seed(0)\n",
    "for _ in range(10000):\n",
    "    younger = random_kid()\n",
    "    older = random_kid()\n",
    "    if older == \"girl\":\n",
    "        older_girl += 1\n",
    "    if older == \"girl\" and younger == \"girl\":\n",
    "        both_girls += 1\n",
    "    if older == \"girl\" or younger == \"girl\":\n",
    "        either_girl += 1\n",
    "    if younger != older:\n",
    "        girl_boy += 1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_girls = 0\n",
    "older_girl = 0\n",
    "either_girl = 0\n",
    "girl_boy = 0\n",
    "\n",
    "random.seed(0)\n",
    "for _ in range(10000):\n",
    "    younger = random_kid()\n",
    "    older = random_kid()\n",
    "    if older == \"girl\":\n",
    "        older_girl += 1\n",
    "    if older == \"girl\" and younger == \"girl\":\n",
    "        both_girls += 1\n",
    "    if older == \"girl\" or younger == \"girl\":\n",
    "        either_girl += 1\n",
    "    if younger != older:\n",
    "        girl_boy += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print('The probability of \"both children are girls (B) conditional on the event the older child is a girl (G)\" is: ' + \\\n",
    "     str(both_girls / older_girl))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of \"both children are girls (B) conditional on the event the older child is a girl (G)\" is: 0.5007089325501317\n"
     ]
    }
   ],
   "source": [
    "print('The probability of \"both children are girls (B) conditional on the event the older child is a girl (G)\" is: ' + \\\n",
    "     str(both_girls / older_girl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print('The probability of \"both children are girls (B) conditional on the event at least one of the children is a girl (L)\" is: ' + \\\n",
    "     str(both_girls / either_girl))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of \"both children are girls (B) conditional on the event at least one of the children is a girl (L)\" is: 0.3311897106109325\n"
     ]
    }
   ],
   "source": [
    "print('The probability of \"both children are girls (B) conditional on the event at least one of the children is a girl (L)\" is: ' + \\\n",
    "     str(both_girls / either_girl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print('The probability of \"one boy one girl (D) conditional on the event one child is a girl (L)\" is: ' + \\\n",
    "     str(girl_boy / either_girl))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of \"one boy one girl (D) conditional on the event one child is a girl (L)\" is: 0.6688102893890675\n"
     ]
    }
   ],
   "source": [
    "print('The probability of \"one boy one girl (D) conditional on the event one child is a girl (L)\" is: ' + \\\n",
    "     str(girl_boy / either_girl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is it that if you know one child is girl then having another child as boy is twice as likely as having another girl?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes’s Theorem\n",
    "One of the data scientist’s best friends is Bayes’s Theorem, which is a way of “reversing”\n",
    "conditional probabilities. Let’s say we need to know the probability of some event\n",
    "E conditional on some other event F occurring. But we only have information about\n",
    "the probability of F conditional on E occurring. Using the definition of conditional\n",
    "probability twice tells us that:\n",
    "\n",
    "$P(E|F) = P(E, F) /P(F) = P(F|E) P(E) /P(F)$\n",
    "\n",
    "The event F can be split into the two mutually exclusive events “F and E” and “F and\n",
    "not E.” If we write ¬E for “not E” (i.e., “E doesn’t happen”), then:\n",
    "\n",
    "$P(F) = P(F, E) + P(F, ¬E)$\n",
    "\n",
    "so that:\n",
    "\n",
    "$P(E|F) = P(F|E) P(E) / P(F|E) P(E) + P(F|¬E) P(¬E)$\n",
    "\n",
    "which is how Bayes’s Theorem is often stated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Imagine a certain disease that affects 1 in every 10,000 people. And imagine\n",
    "that there is a test for this disease that gives the correct result (“diseased” if you have\n",
    "the disease, “nondiseased” if you don’t) 99% of the time. What is the probability of a person having the disease if the person has a positive test? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Variables\n",
    "A random variable is a variable whose possible values have an associated probability\n",
    "distribution. A very simple random variable equals 1 if a coin flip turns up heads and\n",
    "0 if the flip turns up tails. \n",
    "\n",
    "### Expected Value\n",
    "The expected value $E[X]$ of a random varaible $X$ is the average value of $X$ weighted by its probabilities:\n",
    "\n",
    "$E[X]$ = $P(X = x_{1}) x_{1}$ $+ P(X=x_{2}) x_{2}+...+P(X=x_{n}) x_{n}$\n",
    "\n",
    "### Variance\n",
    "The variance of a random variable $X$ is the expected value of the squared deviation from the mean of $X$, $\\mu= E[X]$:\n",
    "\n",
    "$Var(X) = E[(X-\\mu)^2]$\n",
    "\n",
    "### Standard Deviation\n",
    "Standard deviation is the squred root of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Distributions\n",
    "A coin flip corresponds to a discrete distribution—one that associates positive probability\n",
    "with discrete outcomes. Often we’ll want to model distributions across a continuum\n",
    "of outcomes. (For our purposes, these outcomes will always be real numbers,\n",
    "although that’s not always the case in real life.) For example, the uniform distribution\n",
    "puts equal weight on all the numbers between 0 and 1.\n",
    "\n",
    "Because there are infinitely many numbers between 0 and 1, this means that the\n",
    "weight it assigns to individual points must necessarily be zero. For this reason, we\n",
    "represent a continuous distribution with a probability density function (pdf) such that\n",
    "the probability of seeing a value in a certain interval equals the integral of the density\n",
    "function over the interval.\n",
    "\n",
    "We will often be more interested in the cumulative distribution function (cdf), which\n",
    "gives the probability that a random variable is less than or equal to a certain value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Write functions for the probability density function and the cumulative distribtuion function of the uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal Distribution\n",
    "The normal distribution is the king of distributions. It is the classic bell curve–shaped\n",
    "distribution and is completely determined by two parameters: its mean $\\mu$ and its\n",
    "standard deviation $\\sigma$. The mean indicates where the bell is centered, and the\n",
    "standard deviation how “wide” it is.\n",
    "\n",
    "It has the distribution function:\n",
    "\n",
    "$f(x|\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp (-\\frac{(x − \\mu)^2}{2\\sigma^2})$\n",
    "\n",
    "which we can implement as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def normal_pdf(x, mu=0, sigma=1):\n",
    "    sqrt_two_pi = math.sqrt(2 * math.pi)\n",
    "    return (math.exp(-(x-mu) ** 2 / 2 / sigma ** 2) / (sqrt_two_pi * sigma))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009900990099009901"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.99*0.0001)/(0.99*0.0001 + 0.01*0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "xs = [x / 10.0 for x in range(-50, 50)]\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.plot(xs,[normal_pdf(x,sigma=1) for x in xs],'-',label='mu=0,sigma=1')\n",
    "plt.plot(xs,[normal_pdf(x,sigma=2) for x in xs],'--',label='mu=0,sigma=2')\n",
    "plt.plot(xs,[normal_pdf(x,sigma=0.5) for x in xs],':',label='mu=0,sigma=0.5')\n",
    "plt.plot(xs,[normal_pdf(x,mu=-1) for x in xs],'-.',label='mu=-1,sigma=1')\n",
    "plt.legend()\n",
    "plt.title(\"Various Normal pdfs\")\n",
    "plt.grid()\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\mu = 0$ and $\\sigma = 1$, it’s called the standard normal distribution. If Z is a standard\n",
    "normal random variable, then it turns out that:\n",
    "\n",
    "$X = \\sigma Z + \\mu$\n",
    "\n",
    "is also normal but with mean $\\mu$ and standard deviation $\\sigma$. Conversely, if X is a normal\n",
    "random variable with mean $\\mu$ and standard deviation $\\sigma$,\n",
    "\n",
    "$Z = (X − \\mu) /\\sigma$\n",
    "\n",
    "is a standard normal variable -- **Rescalling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Central Limit Theorem\n",
    "\n",
    "One reason the normal distribution is so useful is the central limit theorem, which\n",
    "says (in essence) that a random variable defined as the average of a large number of\n",
    "independent and identically distributed random variables is itself approximately normally\n",
    "distributed.\n",
    "\n",
    "In particular, if $x_{1}, ..., x_{n}$ are random variables with mean $\\mu$ and standard deviation $\\sigma$,\n",
    "and if n is large, then:\n",
    "\n",
    "$(x_{1} + ... + x_{n})/n$\n",
    "\n",
    "is approximately normally distributed with mean $\\mu$ and standard deviation $\\sigma / \\sqrt{(n)}$.\n",
    "Equivalently (but often more usefully),\n",
    "\n",
    "$\\frac{(x_{1} + ... + x_{n}) − \\mu n}{\\sigma \\sqrt{(n)}}$\n",
    "\n",
    "is approximately normally distributed with mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "An easy way to illustrate this is by looking at binomial random variables, which have\n",
    "two parameters n and p. A Binomial(n,p) random variable is simply the sum of n\n",
    "independent Bernoulli(p) random variables, each of which equals 1 with probability p\n",
    "and 0 with probability 1 − p:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def bernoulli_trial(p):\n",
    "    return 1 if random.random() < p else 0\n",
    "def binomial(n, p):\n",
    "    return sum(bernoulli_trial(p) for _ in range(n))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of a Bernoulli(p) variable is $p$, and its standard deviation is $p(1 − p)$. The\n",
    "central limit theorem says that as n gets large, a Binomial(n,p) variable is approximately\n",
    "a normal random variable with mean $\\mu = np$ and standard deviation\n",
    "$\\sigma = \\sqrt{np(1 − p)}$ . If we plot both, you can easily see the resemblance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from collections import Counter\n",
    "def normal_cdf(x, mu=0,sigma=1):\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "def make_hist(p, n, num_points):\n",
    "    data = [binomial(n, p) for _ in range(num_points)]\n",
    "    # use a bar chart to show the actual binomial samples\n",
    "    histogram = Counter(data)\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    plt.bar([x - 0.4 for x in histogram.keys()], \\\n",
    "    [v / num_points for v in histogram.values()], \\\n",
    "    0.8, \\\n",
    "    color='0.75')\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(n * p * (1 - p))\n",
    "    # use a line chart to show the normal approximation\n",
    "    xs = range(min(data), max(data) + 1)\n",
    "    ys = [normal_cdf(i + 0.5, mu, sigma) - normal_cdf(i - 0.5, mu, sigma) for i in xs]\n",
    "    #plt.figure(figsize=(15,9))\n",
    "    plt.plot(xs,ys)\n",
    "    plt.title(\"Binomial Distribution vs. Normal Approximation\")\n",
    "    plt.grid()\n",
    "    plt.show()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "make_hist(0.75, 100, 10000)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
